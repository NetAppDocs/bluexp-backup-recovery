---
sidebar: sidebar
permalink: concept-ontap-backup-to-cloud.html
keywords: backing up, restoring, back up, backup, restore, cloud volumes ontap, aws, azure, s3, blob, google cloud, storagegrid, back up volumes, cloud backup, restore volumes, billing, cost, on-premises ontap, onprem
summary: Cloud Backup provides backup and restore capabilities for protection and long-term archive of your ONTAP cluster data. Backups are automatically generated and stored in an object store in your public or private cloud account, independent of volume Snapshot copies used for near-term recovery or cloning.
---

= Protect your ONTAP cluster data using Cloud Backup
:hardbreaks:
:nofooter:
:icons: font
:linkattrs:
:imagesdir: ./media/

[.lead]
Cloud Backup provides backup and restore capabilities for protection and long-term archive of your ONTAP cluster data. Backups are automatically generated and stored in an object store in your public or private cloud account, independent of volume Snapshot copies used for near-term recovery or cloning.

When necessary, you can restore an entire _volume_, or one or more _files_, from a backup to the same or different working environment.

== Features

Backup features:

* Back up independent copies of your data volumes to low-cost object storage.
* Apply a single backup policy to all volumes in a cluster, or assign different backup policies to volumes that have unique recovery point objectives.
* Make immutable backup files so they are locked for the retention period.
* Scan backup files for possible ransomware attack - and remove/replace infected backups automatically.
* Tier older backup files to archival storage to save costs.
* Back up from cloud to cloud, and from on-premises systems to public or private cloud.
* For Cloud Volumes ONTAP systems, your backups can reside on a different subscription/account or different region.
* Backup data is secured with AES-256 bit encryption at-rest and TLS 1.2 HTTPS connections in-flight.
* Use your own customer-managed keys for data encryption instead of using the default encryption keys from your cloud provider.
* Support for up to 4,000 backups of a single volume.

Restore features:

* Restore data from a specific point in time.
* Restore a volume, or individual files, to the source system or to a different system.
* Restore data to a working environment using a different subscription/account or that is in a different region.
* Restores data on a block level, placing the data directly in the location you specify, all while preserving the original ACLs.
* Browsable and searchable file catalogs for selecting individual files for single file restore.

== Supported ONTAP working environments and object storage providers

Cloud Backup enables you to back up ONTAP volumes from the following working environments to object storage in the following public and private cloud providers:

[cols=2*,options="header",cols="45,45",width="95%"]
|===

| Source Working Environment
| Backup File Destination

ifdef::aws[]
| Cloud Volumes ONTAP in AWS
| Amazon S3
endif::aws[]
ifdef::azure[]
| Cloud Volumes ONTAP in Azure
| Azure Blob
endif::azure[]
ifdef::gcp[]
| Cloud Volumes ONTAP in Google
| Google Cloud Storage
endif::gcp[]
| On-premises ONTAP system
|
ifdef::aws[]
Amazon S3
endif::aws[]
ifdef::azure[]
Azure Blob
endif::azure[]
ifdef::gcp[]
Google Cloud Storage
endif::gcp[]
NetApp StorageGRID

|===

You can restore a volume, or individual files, from an ONTAP backup file to the following working environments:

[cols=3*,options="header",cols="25,33,37",width="95%"]
|===

| Backup File
2+^| Destination Working Environment
| *Location* | *Volume Restore* | *File Restore*
ifdef::aws[]
| Amazon S3 | Cloud Volumes ONTAP in AWS
On-premises ONTAP system
| Cloud Volumes ONTAP in AWS
On-premises ONTAP system
endif::aws[]
ifdef::azure[]
| Azure Blob | Cloud Volumes ONTAP in Azure
On-premises ONTAP system | Cloud Volumes ONTAP in Azure
On-premises ONTAP system
endif::azure[]
ifdef::gcp[]
| Google Cloud Storage | Cloud Volumes ONTAP in Google
On-premises ONTAP system
| Cloud Volumes ONTAP in Google
On-premises ONTAP system
endif::gcp[]
| NetApp StorageGRID | On-premises ONTAP system | On-premises ONTAP system

|===

Note that references to "on-premises ONTAP systems" includes FAS, AFF, and ONTAP Select systems.

=== Support for sites with no internet connectivity

Cloud Backup can be used in a site with no internet connectivity (also known as an "offline" or "dark" site) to back up volume data from local on-premises ONTAP systems to local NetApp StorageGRID systems. Both volume and file restore are also supported in this configuration. In this case, you'll need to deploy the Cloud Manager Connector (minimum version 3.9.20) in the dark site. See link:task-backup-onprem-private-cloud.html[Backing up on-premises ONTAP data to StorageGRID] for details.

== Supported volumes

Cloud Backup supports the following types of volumes:

* FlexVol read-write volumes
* SnapMirror data protection (DP) destination volumes
* SnapLock Enterprise volumes (requires ONTAP 9.11.1 or later)

FlexGroup volumes and SnapLock Compliance volumes aren't currently supported.

== Cost

There are two types of costs associated with using Cloud Backup with ONTAP systems: resource charges and service charges.

*Resource charges*

Resource charges are paid to the cloud provider for object storage capacity and for writing and reading backup files to the cloud.

* For Backup, you pay your cloud provider for object storage costs.
+
Since Cloud Backup preserves the storage efficiencies of the source volume, you pay the cloud provider object storage costs for the data _after_ ONTAP efficiencies (for the smaller amount of data after deduplication and compression have been applied).

* For Volume or File Restore using Search & Restore, certain resources are provisioned by your cloud provider, and there is per-TiB cost associated with the amount of data that is scanned by your search requests.
+
ifdef::aws[]
** In AWS, https://aws.amazon.com/athena/faqs/[Amazon Athena^] and https://aws.amazon.com/glue/faqs/[AWS Glue^] resources are deployed in a new S3 bucket.
+
endif::aws[]
+
ifdef::azure[]
** In Azure, an https://azure.microsoft.com/en-us/services/synapse-analytics/?&ef_id=EAIaIQobChMI46_bxcWZ-QIVjtiGCh2CfwCsEAAYASAAEgKwjvD_BwE:G:s&OCID=AIDcmm5edswduu_SEM_EAIaIQobChMI46_bxcWZ-QIVjtiGCh2CfwCsEAAYASAAEgKwjvD_BwE:G:s&gclid=EAIaIQobChMI46_bxcWZ-QIVjtiGCh2CfwCsEAAYASAAEgKwjvD_BwE[Azure Synapse workspace^] and https://azure.microsoft.com/en-us/services/storage/data-lake-storage/?&ef_id=EAIaIQobChMIuYz0qsaZ-QIVUDizAB1EmACvEAAYASAAEgJH5fD_BwE:G:s&OCID=AIDcmm5edswduu_SEM_EAIaIQobChMIuYz0qsaZ-QIVUDizAB1EmACvEAAYASAAEgJH5fD_BwE:G:s&gclid=EAIaIQobChMIuYz0qsaZ-QIVUDizAB1EmACvEAAYASAAEgJH5fD_BwE[Azure Data Lake Storage^] are provisioned in your storage account to store and analyze your data.
+
endif::azure[]
ifdef::gcp[]
** In Google, a new bucket is deployed, and the https://cloud.google.com/bigquery[Google Cloud BigQuery services^] are provisioned on an account/project level.
endif::gcp[]

* If you need to restore volume data from a backup file that has been moved to archival storage, then there's an additional per-GiB retrieval fee and per-request fee from the cloud provider.

*Service charges*

Service charges are paid to NetApp and cover both the cost to _create_ backups and to _restore_ volumes, or files, from those backups. You pay only for the data that you protect, calculated by the source logical used capacity (_before_ ONTAP efficiencies) of ONTAP volumes which are backed up to object storage. This capacity is also known as Front-End Terabytes (FETB).

There are three ways to pay for the Backup service. The first option is to subscribe from your cloud provider, which enables you to pay per month. The second option is to get an annual contract. The third option is to purchase licenses directly from NetApp. Read the <<Licensing,Licensing>> section for details.

== Licensing

Cloud Backup is available with the following consumption models:

* *BYOL*: A license purchased from NetApp that can be used with any cloud provider.
* *PAYGO*: An hourly subscription from your cloud provider’s marketplace.
* *Annual*: An annual contract from your cloud provider’s marketplace.

[NOTE]
====
If you purchase a BYOL license from NetApp, you also need to subscribe to the PAYGO offering from your cloud provider’s marketplace. Your license is always charged first, but you’ll be charged from the hourly rate in the marketplace in these cases:

* If you exceed your licensed capacity
* If the term of your license expires

If you have an annual contract from a marketplace, all Cloud Backup consumption is charged against that contract. You can’t mix and match an annual marketplace contract with a BYOL.
====

=== Bring your own license

BYOL is term-based (12, 24, or 36 months) _and_ capacity-based in 1 TiB increments. You pay NetApp to use the service for a period of time, say 1 year, and for a maximum amount capacity, say 10 TiB.

You'll receive a serial number that you enter in the Cloud Manager Digital Wallet page to enable the service. When either limit is reached, you'll need to renew the license. The Backup BYOL license applies to all source systems associated with your https://docs.netapp.com/us-en/cloud-manager-setup-admin/concept-netapp-accounts.html[Cloud Manager account^].

link:task-licensing-cloud-backup.html#use-a-cloud-backup-byol-license[Learn how to manage your BYOL licenses].

=== Pay-as-you-go subscription

Cloud Backup offers consumption-based licensing in a pay-as-you-go model. After subscribing through your cloud provider’s marketplace, you pay per GiB for data that’s backed up—​there’s no up-front payment. You are billed by your cloud provider through your monthly bill.

link:task-licensing-cloud-backup.html#use-a-cloud-backup-paygo-subscription[Learn how to set up a pay-as-you-go subscription].

Note that a 30-day free trial is available when you initially sign up with a PAYGO subscription.

=== Annual contract

ifdef::aws[]
When using AWS, two annual contracts are available for 12, 24, or 36 month terms:

*	A "Cloud Backup" plan that enables you to back up Cloud Volumes ONTAP data and on-premises ONTAP data.

* A "CVO Professional" plan that enables you to bundle Cloud Volumes ONTAP and Cloud Backup. This includes unlimited backups for Cloud Volumes ONTAP volumes charged against this license (backup capacity is not counted against the license).
endif::aws[]

ifdef::azure[]
* When using Azure, you can request a private offer from NetApp, and then select the plan when you subscribe from the Azure Marketplace during Cloud Backup activation.
endif::azure[]

ifdef::gcp[]
* When using GCP, you can request a private offer from NetApp, and then select the plan when you subscribe from the Google Cloud Marketplace during Cloud Backup activation.
endif::gcp[]

link:task-licensing-cloud-backup.html#use-an-annual-contract[Learn how to set up annual contracts].

== How Cloud Backup works

When you enable Cloud Backup on a Cloud Volumes ONTAP or on-premises ONTAP system, the service performs a full backup of your data. Volume snapshots are not included in the backup image. After the initial backup, all additional backups are incremental, which means that only changed blocks and new blocks are backed up. This keeps network traffic to a minimum.

In most cases you'll use the Cloud Manager UI for all backup operations. However, starting with ONTAP 9.9.1 you can initiate volume backup operations of your on-premises ONTAP clusters using ONTAP System Manager. https://docs.netapp.com/us-en/ontap/task_cloud_backup_data_using_cbs.html[See how to use System Manager to back up your volumes to the cloud using Cloud Backup.^]

CAUTION: Any actions taken directly from your cloud provider environment to manage or change backup files may corrupt the files and will result in an unsupported configuration.

The following image shows the relationship between each component:

image:diagram_cloud_backup_general.png[A diagram showing how Cloud Backup communicates with the volumes on the source systems and the destination object storage where the backup files are located.]

=== Where backups reside

Backup copies are stored in an object store that Cloud Manager creates in your cloud account. There’s one object store per cluster/working environment, and Cloud Manager names the object store as follows: "netapp-backup-clusteruuid". Be sure not to delete this object store.

ifdef::aws[]
* In AWS, Cloud Manager enables the https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html[Amazon S3 Block Public Access feature^] on the S3 bucket.
endif::aws[]

ifdef::azure[]
* In Azure, Cloud Manager uses a new or existing resource group with a storage account for the Blob container. Cloud Manager https://docs.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access-prevent[blocks public access to your blob data] by default.
endif::azure[]

ifdef::gcp[]
* In GCP, Cloud Manager uses a new or existing project with a storage account for the Google Cloud Storage bucket.
endif::gcp[]

* In StorageGRID, Cloud Manager uses an existing storage account for the object store bucket.

If you want to change the destination object store for a cluster in the future, you'll need to link:task-manage-backups-ontap.html#unregistering-cloud-backup-for-a-working-environment[unregister Cloud Backup for the working environment^], and then enable Cloud Backup using the new cloud provider information.

=== Customizable backup schedule and retention settings

When you enable Cloud Backup for a working environment, all the volumes you initially select are backed up using the default backup policy that you define. If you want to assign different backup policies to certain volumes that have different recovery point objectives (RPO), you can create additional policies for that cluster and assign those policies to the other volumes after Backup is activated.

You can choose a combination of hourly, daily, weekly, monthly, and yearly backups of all volumes. You can also select one of the system-defined policies that provide backups and retention for 3 months, 1 year, and 7 years. These policies are:

[cols=5*,options="header",cols="35,16,16,16,26",width="80%"]
|===
| Backup Policy Name
3+| Backups per interval...
| Max. Backups

|  | *Daily* | *Weekly* | *Monthly* |
| Netapp3MonthsRetention | 30 | 13 | 3
| 46
| Netapp1YearRetention | 30 | 13 | 12
| 55
| Netapp7YearsRetention | 30 | 53 | 84
| 167

|===

Backup protection policies that you have created on the cluster using ONTAP System Manager or the ONTAP CLI will also appear as selections. This includes policies created using custom SnapMirror labels.

Once you have reached the maximum number of backups for a category, or interval, older backups are removed so you always have the most current backups (and so obsolete backups don't continue to take up space in the cloud).

Note that you can link:task-manage-backups-ontap.html#creating-a-manual-volume-backup-at-any-time[create an on-demand backup of a volume] from the Backup Dashboard at any time, in addition to those backup files created from the scheduled backups.

TIP: The retention period for backups of data protection volumes is the same as defined in the source SnapMirror relationship. You can change this if you want by using the API.

=== Backup file protection settings

If your cluster is using ONTAP 9.11.1 or greater, you can protect your backups from deletion and ransomware attacks. Each backup policy provides a section for _DataLock and Ransomware Protection_ that can be applied to your backup files for a specific period of time - the _retention period_. _DataLock_ protects your backup files from being modified or deleted. _Ransomware protection_ scans your backup files to look for evidence of a ransomware attack when a backup file is created, and when data from a backup file is being restored.

You can choose from the following settings for each backup policy:

* None. DataLock protection and ransomware protection are disabled.

* Enterprise. DataLock mode is set to _Enterprise_ where users with specific permissions can overwrite or delete backup files during the retention period. Ransomware protection is enabled.

* Compliance. DataLock mode is set to _Compliance_ where no users can overwrite or delete backup files during the retention period. Ransomware protection is enabled.

The retention period is the same as the schedule retention period; plus 14 days. For example, _weekly_ backups with _5_ copies retained will lock each backup file for 5 weeks. _Monthly_ backups with _6_ copies retained will lock each backup file for 6 months.

Support is currently available when your backup destination is Amazon S3. Other storage provider destinations will be added in future releases.

TIP: DataLock can't be enabled if you are tiering backups to archival storage.

See link:concept-cloud-backup-policies.html#datalock-and-ransomware-protection[DataLock and Ransomware protection^] for more details about how DataLock and Ransomware protection works.

=== Archival storage for older backup files

When using certain cloud storage you can move older backup files to a less expensive storage class/access tier after a certain number of days. Note that archival storage can't be used if you have enabled DataLock.

ifdef::aws[]
* In AWS, backups start in the _Standard_ storage class and transition to the _Standard-Infrequent Access_ storage class after 30 days.
+
If your cluster is using ONTAP 9.10.1 or greater, you can choose to tier older backups to either _S3 Glacier_ or _S3 Glacier Deep Archive_ storage in the Cloud Backup UI after a certain number of days for further cost optimization. link:reference-aws-backup-tiers.html[Learn more about AWS archival storage^].
+
Note that if you choose _S3 Glacier_ or _S3 Glacier Deep Archive_ in your first backup policy when activating Cloud Backup, then that tier will be the only archive tier available for future backup policies for that cluster. And if you select no archive tier in your first backup policy, then _S3 Glacier_ will be your only archive option for future policies.
endif::aws[]

ifdef::azure[]
* In Azure, backups are associated with the _Cool_ access tier.
+
If your cluster is using ONTAP 9.10.1 or greater, you can choose to tier older backups to _Azure Archive_ storage in the Cloud Backup UI after a certain number of days for further cost optimization. link:reference-azure-backup-tiers.html[Learn more about Azure archival storage^].
endif::azure[]

ifdef::gcp[]
* In GCP, backups are associated with the _Standard_ storage class by default.
+
You can also use the lower cost _Nearline_ storage class, or the _Coldline_ or _Archive_ storage classes. You configure these other storage classes through Google. See the Google topic link:https://cloud.google.com/storage/docs/storage-classes[Storage classes^] for information about changing the storage class.
endif::gcp[]

* In StorageGRID, backups are associated with the _Standard_ storage class.

== FabricPool tiering policy considerations

There are certain things you need to be aware of when the volume you are backing up resides on a FabricPool aggregate and it has an assigned policy other than `none`:

* The first backup of a FabricPool-tiered volume requires reading all local and all tiered data (from the object store). A backup operation does not "reheat" the cold data tiered in object storage.
+
This operation could cause a one-time increase in cost to read the data from your cloud provider.

** Subsequent backups are incremental and do not have this effect.
** If the tiering policy is assigned to the volume when it is initially created you will not see this issue.

* Consider the impact of backups before assigning the `all` tiering policy to volumes. Because data is tiered immediately, Cloud Backup will read data from the cloud tier rather than from the local tier. Because concurrent backup operations share the network link to the cloud object store, performance degradation might occur if network resources become saturated. In this case, you may want to proactively configure multiple network interfaces (LIFs) to decrease this type of network saturation.

== Limitations

The following is a known issue that will be fixed in a future release:

* During a restore operation, if the backup was created on a system running ONTAP version 9.10.1 or later, and the system where the volume is being restored is running ONTAP version 9.10.0 or earlier, then the restore fails with either system disruption or in some cases the restore is successful, but the volume is corrupted.

=== Backup limitations

* The ability to tier older backup files to archival storage requires that the cluster is running ONTAP 9.10.1 or greater. Restoring volumes from backup files that reside in archival storage also requires that the destination cluster is running ONTAP 9.10.1+.

* When creating or editing a backup policy when no volumes are assigned to the policy, the number of retained backups can be a maximum of 1018. As a workaround you can reduce the number of backups to create the policy. Then you can edit the policy to create up to 4000 backups after you assign volumes to the policy.

* When backing up data protection (DP) volumes:
** Relationships with the SnapMirror labels `app_consistent` and `all_source_snapshot` won't be backed up to cloud.
** If you create local copies of Snapshots on the SnapMirror destination volume (irrespective of the SnapMirror labels used) these Snapshots will not be moved to the cloud as backups. At this time you’ll need to create a Snapshot policy with the desired labels to the source DP volume in order for Cloud Backup to back them up.

* SVM-DR volume backup is supported with the following restrictions:
** Backups are supported from the ONTAP secondary only.
** The Snapshot policy applied to the volume must be one of the policies recognized by Cloud Backup, including daily, weekly, monthly, etc. The default "sm_created" policy (used for *Mirror All Snapshots*) is not recognized and the DP volume will not be shown in the list of volumes that can be backed up.

* Ad-hoc volume backup using the *Backup Now* button isn't supported on data protection volumes.

* SM-BC configurations are not supported.

* MetroCluster (MCC) backup is supported from ONTAP secondary only: MCC > SnapMirror > ONTAP > Cloud Backup > object storage.

* ONTAP doesn't support fan-out of SnapMirror relationships from a single volume to multiple object stores; therefore, this configuration is not supported by Cloud Backup.

* WORM/Compliance mode on an object store is only supported on Amazon S3 at this time.

=== Single File Restore limitations

These limitations apply to both the Search & Restore and the Browse & Restore methods of restoring files; unless called out specifically.

* Browse & Restore can restore up to 100 individual files at a time.

* Search & Restore can restore 1 file at a time.

* There is currently no support for restoring folders/directories.

* The file being restored must be using the same language as the language on the destination volume. You will receive an error message if the languages are not the same.

* File level restore is not supported when using the same account with different Cloud Managers in different subnets.

* You can’t restore individual files if the backup file resides in archival storage.

* File level restore using Search & Restore is not supported when the Connector is installed on a site without internet access (dark site).
